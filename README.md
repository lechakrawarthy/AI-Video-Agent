# AI Video / Shorts Generator Agent

An AI-powered application that converts text input into short-form videos using:
- LLM-based script generation
- AI image creation (DALL-E)
- AI voice-over (TTS)
- FFmpeg video assembly

## ğŸš€ Quick Start

### Prerequisites
- **Python 3.8+**
- **Node.js 16+**
- **FFmpeg** (installed and in PATH)
- **OpenAI API Key** (for AI features)

### 1ï¸âƒ£ Backend Setup

```bash
cd backend

# Install dependencies
pip install -r requirements.txt

# Configure environment (optional for now)
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY

# Start the server
python -m uvicorn app.main:app --reload
```

Backend will run on: `http://127.0.0.1:8000`

### 2ï¸âƒ£ Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm run dev
```

Frontend will run on: `http://localhost:5173` (or next available port)

### 3ï¸âƒ£ Access the Application

Open your browser to the frontend URL (shown in terminal after `npm run dev`)

## ğŸ“‹ Features

- ğŸ“ Script generation based on topic and description
- ğŸ¨ Scene-by-scene content planning
- ğŸ¤ Voice-over generation
- ğŸ–¼ï¸ Image generation for each scene
- ğŸ¬ Automated video assembly
- âš™ï¸ Customizable tone, voice, and duration

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **OpenAI API** - GPT for scripts, DALL-E for images, TTS for voice
- **FFmpeg** - Video assembly
- **Pydantic** - Data validation

### Frontend
- **React** - UI framework
- **TypeScript** - Type-safe JavaScript
- **Vite** - Build tool
- **Tailwind CSS** - Styling

## ğŸ“ Project Structure

```
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/          # AI agent modules
â”‚   â”‚   â”‚   â”œâ”€â”€ script_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ image_agent.py
â”‚   â”‚   â”‚   â”œâ”€â”€ voice_agent.py
â”‚   â”‚   â”‚   â””â”€â”€ video_agent.py
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI application
â”‚   â”‚   â”œâ”€â”€ models.py        # Data models
â”‚   â”‚   â””â”€â”€ orchestrator.py  # Main workflow
â”‚   â”œâ”€â”€ outputs/             # Generated files
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”œâ”€â”€ pages/           # Page components
â”‚   â”‚   â”œâ”€â”€ api.ts           # API client
â”‚   â”‚   â””â”€â”€ main.tsx         # Entry point
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

## ğŸ¯ Use Cases

- ğŸ“± Social media content creation
- ğŸ“¢ Marketing reels and ads
- ğŸ“š Educational shorts
- ğŸ¥ Quick video prototypes

## ğŸ”§ Troubleshooting

### Backend Issues
- **Port already in use**: Change port with `--port 8001`
- **Module not found**: Run `pip install -r requirements.txt`
- **CORS errors**: Check frontend URL in CORS settings

### Frontend Issues
- **Port in use**: Vite will auto-select next available port
- **Styles not loading**: Ensure dev server is running
- **API errors**: Verify backend is running on port 8000

## ğŸ“ Development Notes

Currently, the application uses placeholder/mock implementations for:
- Image generation (creates empty files)
- Voice generation (creates empty files)
- Video assembly (creates empty file)

To enable full AI features, add your OpenAI API key to `.env` and implement the actual API calls in the agent files.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“„ License

MIT License - feel free to use this project for learning or production.
